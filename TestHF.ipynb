{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# OpenAI + Pinecone"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"OpenAI + Pinecone",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "sheet_delimiter":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Searching with populated context \n",
    "\n",
    "Uses the indexed embeddings in pinecone, to fetch closest matching paragraphs, to provide OpenAI with more context, during QnA\n",
    "\n",
    "### Used libraries\n",
    "- OpenAI: For creating embeddings from paragraphs within chapters\n",
    "- Pinecone: Used to store and search by cosine-similarity across embeddings\n",
    "- Retry: Used for retrying failures accessing APIs"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"41NND3lynWyj7GQR0sDm4G",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import openai\n",
    "import os\n",
    "import pinecone\n",
    "index_name = 'sheshadri-swamigalv1'\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "openai.api_key = os.environ[\"API\"]\n",
    "from retry import retry\n",
    "\n",
    "limit = 3750\n",
    "@retry(tries=10)\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    prompt=\"\"\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=400,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "pinecone.init(\n",
    "        api_key=os.environ[\"PC_API\"],\n",
    "        environment=\"us-east1-gcp\"\n",
    "    )\n",
    "index = pinecone.Index(index_name)\n",
    "print(complete(retrieve(\"What is the area of kanchi district?\")))"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "400 Sq. Miles\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/pinecone\/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"oTkwEjwJccAQF6dr0vC9T4",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "version":1,
   "computation_mode":"REACTIVE",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"datasets",
     "version":"2.10.0",
     "source":"PIP"
    },
    {
     "name":"farm-haystack",
     "version":"1.14.0rc2",
     "source":"PIP"
    },
    {
     "name":"openai",
     "version":"0.26.5",
     "source":"PIP"
    },
    {
     "name":"pinecone-client",
     "source":"PIP"
    },
    {
     "name":"retry",
     "version":"0.9.2",
     "source":"PIP"
    }
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}